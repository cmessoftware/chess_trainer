"""
ğŸ¯ Entrenamiento RÃ¡pido sin MLflow para Prueba
Version simplificada para validar funcionalidad bÃ¡sica
"""

import pandas as pd
from pathlib import Path
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import logging

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def quick_train():
    """Entrenamiento rÃ¡pido para validar funcionalidad"""
    
    print("ğŸš€ ENTRENAMIENTO RÃPIDO (SIN MLFLOW)")
    print("=" * 50)
    
    # Cargar dataset pequeÃ±o
    dataset_path = Path("data/export/unified_small_sources.parquet")
    
    if not dataset_path.exists():
        logger.error("âŒ Dataset no encontrado")
        return
    
    logger.info(f"ğŸ“Š Cargando: {dataset_path}")
    df = pd.read_parquet(dataset_path)
    
    # Tomar muestra pequeÃ±a para prueba rÃ¡pida
    sample_size = min(10000, len(df))
    df_sample = df.sample(n=sample_size, random_state=42)
    logger.info(f"ğŸ“ Muestra: {len(df_sample)} registros")
    
    # Preparar datos
    exclude_cols = ['error_label', 'pgn', 'game_id', 'move_san', 'fen', 'uci']
    feature_cols = [col for col in df_sample.columns if col not in exclude_cols]
    
    # Verificar que tenemos target
    if 'error_label' not in df_sample.columns:
        logger.error("âŒ No se encontrÃ³ columna 'error_label'")
        return
    
    X = df_sample[feature_cols].copy()
    y = df_sample['error_label'].copy()
    
    logger.info(f"ğŸ”§ Features: {len(feature_cols)}")
    logger.info(f"ğŸ¯ Target classes: {y.nunique()}")
    
    # Rellenar valores faltantes rÃ¡pidamente
    X = X.fillna(0)
    
    # Verificar distribuciÃ³n del target
    target_dist = y.value_counts()
    logger.info("ğŸ¯ DistribuciÃ³n del target:")
    for label, count in target_dist.items():
        logger.info(f"   {label}: {count} ({count/len(y)*100:.1f}%)")
    
    # Split datos
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    logger.info(f"ğŸ“Š Train: {len(X_train)}, Test: {len(X_test)}")
    
    # Modelo simple
    model = RandomForestClassifier(
        n_estimators=50,  # Reducido para velocidad
        max_depth=5,      # Reducido para velocidad
        random_state=42,
        n_jobs=-1
    )
    
    # Entrenar
    logger.info("ğŸ”„ Entrenando modelo...")
    model.fit(X_train, y_train)
    
    # Evaluar
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    
    # Resultados
    print("\nğŸ“Š RESULTADOS")
    print("=" * 30)
    print(f"ğŸ¯ Accuracy: {accuracy:.4f}")
    print("\nğŸ“ˆ Reporte por clase:")
    print(classification_report(y_test, y_pred))
    
    # Feature importance
    feature_importance = dict(zip(feature_cols, model.feature_importances_))
    top_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:10]
    
    print("\nğŸ”§ Top 10 Features:")
    for i, (feature, importance) in enumerate(top_features, 1):
        print(f"   {i:2}. {feature}: {importance:.4f}")
    
    # Verificar features importantes
    important_features = [f for f, imp in top_features if imp > 0.05]
    logger.info(f"ğŸ” Features importantes (>5%): {len(important_features)}")
    
    if accuracy > 0.3:  # Umbral bÃ¡sico
        print("\nâœ… ENTRENAMIENTO EXITOSO")
        print("ğŸš€ El modelo bÃ¡sico funciona correctamente")
        print("ğŸ“ˆ Puedes proceder con MLflow tracking")
    else:
        print("\nâš ï¸ ACCURACY BAJA")
        print("ğŸ” Revisar calidad de datos o preprocesamiento")
    
    return model, accuracy

if __name__ == "__main__":
    quick_train()
