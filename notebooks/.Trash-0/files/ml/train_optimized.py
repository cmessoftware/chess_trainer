"""
üéØ Entrenamiento Optimizado con MLflow
Version que funciona con los datos reales disponibles
"""

import pandas as pd
from pathlib import Path
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import mlflow
import mlflow.sklearn
import logging

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def setup_mlflow():
    """Configurar MLflow tracking"""
    try:
        mlflow.set_tracking_uri("http://localhost:5000")
        mlflow.set_experiment("chess_error_prediction")
        logger.info("‚úÖ MLflow configurado correctamente")
        return True
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è MLflow no disponible: {e}")
        return False

def load_and_prepare_data():
    """Cargar y preparar datos optimizados"""
    
    # Cargar dataset
    dataset_path = Path("data/export/unified_small_sources.parquet")
    logger.info(f"üìä Cargando: {dataset_path}")
    
    df = pd.read_parquet(dataset_path)
    logger.info(f"üìè Shape original: {df.shape}")
    
    # Filtrar solo filas con error_label v√°lido
    df_valid = df[df['error_label'].notna()]
    logger.info(f"üìè Shape con labels v√°lidos: {df_valid.shape}")
    
    # Tomar muestra manejable para demo
    sample_size = min(15000, len(df_valid))
    df_sample = df_valid.sample(n=sample_size, random_state=42)
    logger.info(f"üìè Muestra final: {len(df_sample)}")
    
    # Features disponibles
    numeric_features = [
        'material_balance', 'material_total', 'num_pieces', 
        'branching_factor', 'self_mobility', 'opponent_mobility',
        'score_diff', 'move_number', 'white_elo', 'black_elo'
    ]
    
    # Verificar features disponibles
    available_features = [f for f in numeric_features if f in df_sample.columns]
    logger.info(f"üîß Features disponibles: {len(available_features)}")
    
    # Preparar datos
    X = df_sample[available_features].fillna(0)
    y = df_sample['error_label']
    
    # Informaci√≥n del target
    target_dist = y.value_counts()
    logger.info("üéØ Distribuci√≥n del target:")
    for label, count in target_dist.items():
        logger.info(f"   {label}: {count} ({count/len(y)*100:.1f}%)")
    
    return X, y, available_features

def train_with_mlflow(X, y, feature_names, mlflow_enabled=True):
    """Entrenar modelo con MLflow tracking"""
    
    # Split datos
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    logger.info(f"üìä Train: {len(X_train)}, Test: {len(X_test)}")
    
    # Configurar modelo
    model = RandomForestClassifier(
        n_estimators=100,
        max_depth=10,
        random_state=42,
        n_jobs=-1
    )
    
    if mlflow_enabled:
        # MLflow tracking
        with mlflow.start_run(run_name="optimized_chess_classifier"):
            
            # Log par√°metros del dataset
            mlflow.log_param("dataset_source", "unified_small_sources")
            mlflow.log_param("n_samples", len(X))
            mlflow.log_param("n_features", len(feature_names))
            mlflow.log_param("target_classes", y.nunique())
            mlflow.log_param("train_samples", len(X_train))
            mlflow.log_param("test_samples", len(X_test))
            
            # Log par√°metros del modelo
            mlflow.log_params(model.get_params())
            
            # Entrenar
            logger.info("üîÑ Entrenando modelo...")
            model.fit(X_train, y_train)
            
            # Predicciones
            y_pred = model.predict(X_test)
            
            # M√©tricas principales
            accuracy = accuracy_score(y_test, y_pred)
            mlflow.log_metric("accuracy", accuracy)
            mlflow.log_metric("n_classes", len(y.unique()))
            
            # Reporte de clasificaci√≥n detallado
            report = classification_report(y_test, y_pred, output_dict=True)
            for label, metrics in report.items():
                if isinstance(metrics, dict):
                    for metric, value in metrics.items():
                        mlflow.log_metric(f"{label}_{metric}", value)
            
            # Feature importance
            feature_importance = dict(zip(feature_names, model.feature_importances_))
            top_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)
            
            # Log top 5 features
            for i, (feature, importance) in enumerate(top_features[:5]):
                mlflow.log_metric(f"top_feature_{i+1}_importance", importance)
                mlflow.log_param(f"top_feature_{i+1}_name", feature)
            
            # Log modelo
            mlflow.sklearn.log_model(
                model, 
                "chess_error_classifier",
                registered_model_name="ChessErrorClassifier"
            )
            
            # Log informaci√≥n adicional
            mlflow.log_text(
                classification_report(y_test, y_pred), 
                "classification_report.txt"
            )
            
            logger.info(f"‚úÖ Modelo registrado en MLflow - Accuracy: {accuracy:.4f}")
    
    else:
        # Entrenar sin MLflow
        logger.info("üîÑ Entrenando modelo (sin MLflow)...")
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        logger.info(f"‚úÖ Modelo entrenado - Accuracy: {accuracy:.4f}")
    
    # Reporte detallado en consola
    print("\nüìä REPORTE DETALLADO")
    print("=" * 50)
    print(f"üéØ Accuracy: {accuracy:.4f}")
    print("\nüìà Reporte por clase:")
    print(classification_report(y_test, y_pred))
    
    # Top features
    feature_importance = dict(zip(feature_names, model.feature_importances_))
    top_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)
    
    print("\nüîß Top 5 Features m√°s importantes:")
    for i, (feature, importance) in enumerate(top_features[:5], 1):
        print(f"   {i}. {feature}: {importance:.4f}")
    
    return model, accuracy

def main():
    """Funci√≥n principal optimizada"""
    
    print("üöÄ ENTRENAMIENTO OPTIMIZADO CON MLFLOW")
    print("=" * 50)
    
    # Configurar MLflow
    mlflow_enabled = setup_mlflow()
    
    try:
        # Cargar y preparar datos
        X, y, feature_names = load_and_prepare_data()
        
        # Entrenar modelo
        model, accuracy = train_with_mlflow(X, y, feature_names, mlflow_enabled)
        
        # Recomendaciones finales
        print("\nüéØ PR√ìXIMOS PASOS")
        print("=" * 30)
        
        if mlflow_enabled:
            print("1. üåê Revisar MLflow UI: http://localhost:5000")
            print("2. üìä Comparar con otros experimentos")
            print("3. üîÆ Hacer predicciones: python src/ml/make_predictions.py")
        else:
            print("1. üîß Iniciar MLflow para tracking completo")
            print("2. üîÆ Usar modelo para predicciones locales")
        
        print("4. ‚öôÔ∏è Optimizar hiperpar√°metros si es necesario")
        print("5. üé≤ Probar con diferentes datasets")
        
        if accuracy > 0.8:
            print(f"\nüéâ ¬°EXCELENTE RENDIMIENTO!")
            print(f"   Accuracy {accuracy:.4f} > 80% - Modelo listo para producci√≥n")
        elif accuracy > 0.6:
            print(f"\n‚úÖ Buen rendimiento")
            print(f"   Accuracy {accuracy:.4f} - Considera optimizaci√≥n")
        else:
            print(f"\n‚ö†Ô∏è Rendimiento mejorable")
            print(f"   Accuracy {accuracy:.4f} - Revisar features o datos")
        
    except Exception as e:
        logger.error(f"‚ùå Error durante el entrenamiento: {e}")
        raise

if __name__ == "__main__":
    main()
