# ğŸ”® PREDICCIONES ML CON MLFLOW - GUÃA RÃPIDA

## ğŸš€ Inicio RÃ¡pido (2 minutos)

### OpciÃ³n 1: EjecuciÃ³n AutomÃ¡tica (Recomendada)
```powershell
# Ejecutar todo automÃ¡ticamente
.\mlflow-predictions.ps1
```

### OpciÃ³n 2: EjecuciÃ³n Manual Paso a Paso
```powershell
# 1. Iniciar servicios
docker-compose up -d

# 2. AnÃ¡lisis de datos
python src/ml/explore_datasets.py

# 3. Entrenar modelo
python src/ml/train_basic_model.py

# 4. Hacer predicciones
python src/ml/make_predictions.py
```

### OpciÃ³n 3: Pipeline Completo
```powershell
python src/ml/run_complete_pipeline.py
```

---

## ğŸ“Š Â¿QuÃ© hace cada script?

### ğŸ” `explore_datasets.py`
- Analiza todos los datasets disponibles
- Muestra estadÃ­sticas de calidad de datos
- Identifica features tÃ¡cticas y ELO standardizadas
- Recomienda estrategia de experimentaciÃ³n

**Salida esperada:**
```
ğŸ“Š Dataset: unified_all
   ğŸ“Š Shape: (15000, 45)
   ğŸ¯ Target distribution:
      good: 8500 (56.7%)
      mistake: 3200 (21.3%)
      inaccuracy: 2100 (14.0%)
      blunder: 1200 (8.0%)
   âš”ï¸ Features tÃ¡cticas: 8
   ğŸ¯ Columnas ELO: ['white_elo', 'black_elo', 'standardized_white_elo', 'standardized_black_elo']
```

### ğŸ¯ `train_basic_model.py`
- Entrena modelo RandomForest con MLflow tracking
- EvalÃºa rendimiento con mÃ©tricas detalladas
- Registra modelo en MLflow Model Registry
- Muestra feature importance

**Salida esperada:**
```
âœ… Modelo entrenado - Accuracy: 0.8542
ğŸ“Š REPORTE DETALLADO
ğŸ¯ Accuracy: 0.8542

ğŸ”§ Top 10 Features mÃ¡s importantes:
   1. score_diff: 0.2341
   2. material_balance: 0.1789
   3. depth_score_diff: 0.1456
   4. threatens_mate: 0.0987
   5. standardized_white_elo: 0.0834
```

### ğŸ”® `make_predictions.py`
- Carga el mejor modelo desde MLflow
- Hace predicciones en nuevos datos
- Analiza confianza de predicciones
- Guarda resultados en archivo Parquet

**Salida esperada:**
```
âœ… Mejor modelo cargado - Accuracy: 0.8542
ğŸ”® Generando predicciones...
ğŸ“Š DistribuciÃ³n de predicciones:
   good: 5670 (56.7%)
   mistake: 2130 (21.3%)
   inaccuracy: 1400 (14.0%)
   blunder: 800 (8.0%)
ğŸ¯ Confianza promedio: 0.847
ğŸ’¾ Predicciones guardadas en: predictions_output.parquet
```

### ğŸš€ `run_complete_pipeline.py`
- Ejecuta todo el pipeline automÃ¡ticamente
- Maneja errores y timeouts
- Proporciona reporte final
- Ofrece experimentos adicionales

---

## ğŸ“ˆ InterpretaciÃ³n de Resultados

### ğŸ¯ MÃ©tricas de EvaluaciÃ³n

| MÃ©trica       | DescripciÃ³n                  | Valor Objetivo |
| ------------- | ---------------------------- | -------------- |
| **Accuracy**  | PrecisiÃ³n general del modelo | > 0.80         |
| **Precision** | PrecisiÃ³n por clase de error | > 0.75         |
| **Recall**    | Recall por clase de error    | > 0.70         |
| **F1-Score**  | Promedio armÃ³nico P/R        | > 0.75         |

### ğŸ”® Confianza de Predicciones

| Rango     | InterpretaciÃ³n  | AcciÃ³n Recomendada           |
| --------- | --------------- | ---------------------------- |
| > 0.90    | Alta confianza  | Usar predicciÃ³n directamente |
| 0.70-0.90 | Confianza media | Revisar contexto             |
| 0.50-0.70 | Baja confianza  | AnÃ¡lisis manual requerido    |
| < 0.50    | Muy incierta    | No usar predicciÃ³n           |

### âš”ï¸ Features MÃ¡s Importantes

1. **`score_diff`** - Diferencia de evaluaciÃ³n Stockfish
2. **`material_balance`** - Balance material en la posiciÃ³n
3. **`depth_score_diff`** - Diferencia por profundidad (Feature tÃ¡ctica)
4. **`threatens_mate`** - Amenaza de mate (Feature tÃ¡ctica)
5. **`standardized_elo`** - ELO estandarizado (Issue #21)

---

## ğŸŒ MLflow UI - NavegaciÃ³n

### Acceso
- **URL**: http://localhost:5000
- **Experimentos**: "chess_error_prediction"

### Secciones Importantes

#### ğŸ“Š Experiments
- Lista de todos los runs de entrenamiento
- ComparaciÃ³n de mÃ©tricas entre modelos
- Filtrado y ordenamiento por accuracy

#### ğŸ† Models
- Modelo registrado: "ChessErrorClassifier"
- Versiones disponibles
- Staging/Production deployment

#### ğŸ“ˆ Run Details
- ParÃ¡metros del modelo
- MÃ©tricas detalladas
- Artefactos (matriz de confusiÃ³n)
- Feature importance

---

## ğŸ”§ Troubleshooting

### âŒ Error: "No se encontraron datasets"
```powershell
# Verificar datasets disponibles
ls data/export/

# Si no existen, ejecutar pipeline de datos
python src/pipeline/generate_datasets.py
```

### âŒ Error: "MLflow no disponible"
```powershell
# Iniciar servicios Docker
docker-compose up -d mlflow

# Verificar servicios
docker ps | grep mlflow
```

### âŒ Error: "Modelo no encontrado"
```powershell
# Entrenar modelo primero
python src/ml/train_basic_model.py

# Verificar en MLflow UI
start http://localhost:5000
```

### âŒ Error: "Missing values"
```powershell
# Verificar calidad de datos
python src/ml/explore_datasets.py

# Regenerar datasets si es necesario
python src/ml/preprocess_data.py
```

---

## ğŸ¯ Experimentos Avanzados

### 1. ğŸ“Š ComparaciÃ³n por Fuentes
```python
# Comparar rendimiento entre elite, novice, personal
datasets = ["elite", "novice", "personal", "fide"]
for dataset in datasets:
    train_model_for_source(dataset)
```

### 2. âš™ï¸ OptimizaciÃ³n de HiperparÃ¡metros
```python
# Grid search con MLflow tracking
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 15, None]
}
optimize_hyperparameters(param_grid)
```

### 3. âš”ï¸ Experimento Features TÃ¡cticas
```python
# Comparar: solo tÃ¡cticas vs estÃ¡ndar vs combinadas
compare_feature_sets([
    "tactical_only",
    "standard_only", 
    "combined"
])
```

### 4. ğŸ² Ensemble Models
```python
# Combinar mÃºltiples modelos
models = [RandomForest, GradientBoosting, XGBoost]
train_ensemble(models)
```

---

## ğŸ“š PrÃ³ximos Pasos

### ğŸ”® Predicciones en Tiempo Real
```python
from src.ml.realtime_predictor import RealTimeChessPredictor

predictor = RealTimeChessPredictor()
result = predictor.predict_from_fen("fen_string")
```

### ğŸŒ API REST
```python
# Implementar endpoint de predicciones
@app.post("/predict")
def predict_move_error(position: ChessPosition):
    return predictor.predict(position)
```

### ğŸ“Š Dashboard Interactivo
```python
# Streamlit dashboard para visualizar predicciones
streamlit run src/pages/ml_dashboard.py
```

### ğŸ§ª A/B Testing
```python
# Comparar diferentes versiones del modelo
test_model_versions(["v1.0", "v2.0"])
```

---

## ğŸ‰ Resultado Esperado

Al finalizar esta guÃ­a, tendrÃ¡s:

âœ… **Modelo ML entrenado** con accuracy > 80%  
âœ… **Sistema de predicciones** funcionando  
âœ… **MLflow tracking** configurado  
âœ… **AnÃ¡lisis de confianza** implementado  
âœ… **ELO standardization** integrado (Issue #21)  
âœ… **Features tÃ¡cticas** disponibles  
âœ… **Pipeline automatizado** listo para producciÃ³n  

Â¡Listo para hacer predicciones inteligentes de errores de ajedrez! ğŸš€â™Ÿï¸
