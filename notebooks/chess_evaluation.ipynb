{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb7e1cb7",
   "metadata": {},
   "source": [
    "## 📊 Chess Evaluation\n",
    "About Dataset\n",
    "This is a dataset containing around 16 million chess positions with a Stockfish evaluation at depth 22. MIT license. Please help contribute using https://github.com/r2dev2bb8/ChessDataContributor. The Mac and Windows releases somewhat work. Linux has not been tested yet. The dataset will be updated around once a week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52ea05d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.12-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/site-packages (from kagglehub) (24.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->kagglehub) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->kagglehub) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->kagglehub) (2025.4.26)\n",
      "Downloading kagglehub-0.3.12-py3-none-any.whl (67 kB)\n",
      "Installing collected packages: kagglehub\n",
      "Successfully installed kagglehub-0.3.12\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/ronakbadhe/chess-evaluations?dataset_version_number=5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200M/200M [00:09<00:00, 21.1MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /root/.cache/kagglehub/datasets/ronakbadhe/chess-evaluations/versions/5\n"
     ]
    }
   ],
   "source": [
    "%pip install kagglehub\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"ronakbadhe/chess-evaluations\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274750c7",
   "metadata": {},
   "source": [
    "## Chess Evaluation CNN (TensorFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4862f895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chess in /usr/local/lib/python3.11/site-packages (1.11.2)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (1.26.4)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/site-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/site-packages (from tensorflow) (65.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/site-packages (from tensorflow) (4.13.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.73.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.10.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.16.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.73.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.3.0-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.16.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (416 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, optree, opt-einsum, ml-dtypes, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/19\u001b[0m [tensorflow]9\u001b[0m [tensorflow]]data-server]\n",
      "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.3.0 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.73.0 h5py-3.14.0 keras-3.10.0 libclang-18.1.1 ml-dtypes-0.5.1 namex-0.1.0 opt-einsum-3.4.0 optree-0.16.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-3.1.0 wrapt-1.17.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 18:04:10.898956: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-14 18:04:10.926815: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-14 18:04:10.942882: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749924250.975742   38426 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749924250.981605   38426 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749924251.000926   38426 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749924251.000960   38426 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749924251.000963   38426 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749924251.000965   38426 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-14 18:04:11.006924: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%pip install chess tensorflow pandas numpy\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, optimizers\n",
    "import pandas as pd\n",
    "import chess\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91914ee",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Converting FEN notation to tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5b767d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from modules.ml_utils import fen_to_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565a1a63",
   "metadata": {},
   "source": [
    "## Data loader + Label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38659f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from CSV\n",
    "def load_data(csv_path,sample_size=1000):\n",
    "    data = pd.read_csv(csv_path)\n",
    "    data = data.sample(n=sample_size, random_state=42)\n",
    "    boards, active_players, halfmove_clocks, evaluations = [], [], [], []\n",
    "    for idx, row in data.iterrows():\n",
    "        board_tensor, active_player, halfmove_clock = fen_to_tensor(row['FEN'])\n",
    "        boards.append(board_tensor)\n",
    "        active_players.append(active_player)\n",
    "        halfmove_clocks.append(halfmove_clock)\n",
    "        evaluation=row['Evaluation']\n",
    "\n",
    "        if evaluation.startswith('#'):\n",
    "            # Converting checkmate to large positive/negative values\n",
    "            if evaluation[1] == '-':\n",
    "                # Negative checkmate (opponent checkmating)\n",
    "                evaluation = -10000.0  # Arbitrary large negative value\n",
    "            else:\n",
    "                # Positive checkmate (current player checkmating)\n",
    "                evaluation = 10000.0  # Arbitrary large positive value\n",
    "        else:\n",
    "            # Standard centipawn evaluation to float\n",
    "            evaluation = float(evaluation)\n",
    "        \n",
    "        evaluations.append(evaluation)\n",
    "\n",
    "    boards = np.array(boards)\n",
    "    active_players = np.array(active_players)\n",
    "    halfmove_clocks = np.array(halfmove_clocks)\n",
    "    evaluations = np.array(evaluations)\n",
    "    return boards, active_players, halfmove_clocks, evaluations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a6950c",
   "metadata": {},
   "source": [
    "## Model architecture\n",
    "Conditional Batch Normalization\n",
    "Used to distinguish between black & white turns to play when training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671d16dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Conditional Batch Norm Layer\n",
    "class ConditionalBatchNorm(layers.Layer):\n",
    "    def __init__(self, num_features, num_conditions):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.bn = layers.BatchNormalization(center=False, scale=False)\n",
    "        self.gamma = layers.Embedding(num_conditions, num_features, embeddings_initializer='ones')\n",
    "        self.beta = layers.Embedding(num_conditions, num_features, embeddings_initializer='zeros')\n",
    "\n",
    "    def call(self, x, condition):\n",
    "        normalized = self.bn(x)\n",
    "        gamma = self.gamma(condition)[:, tf.newaxis, tf.newaxis, :]\n",
    "        beta = self.beta(condition)[:, tf.newaxis, tf.newaxis, :]\n",
    "        return gamma * normalized + beta"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "6c6f01b9",
   "metadata": {},
   "source": [
    "## ¿Qué es BatchNormalization?\n",
    "\n",
    "BatchNormalization es una técnica muy usada en redes neuronales profundas para estabilizar y acelerar el entrenamiento. Funciona normalizando las activaciones de cada mini-batch durante el entrenamiento. En concreto, para cada feature:\n",
    "\n",
    "​\n",
    "  ![image.png](attachment:image.png)\n",
    "\n",
    "# ¿Qué hace este código?\n",
    "El código define una capa personalizada de Batch Normalization condicional, conocida como:\n",
    "\n",
    "🔧 ConditionalBatchNorm\n",
    "Esta es una variación de BatchNormalization que modula la salida según una condición externa (por ejemplo, una clase o dominio). Se usa en arquitecturas como GANs condicionales, style transfer, y otras tareas donde la red debe comportarse diferente según una entrada auxiliar.\n",
    "\n",
    "🔍 Desglose del código:\n",
    "```python\n",
    "\n",
    "class ConditionalBatchNorm(layers.Layer):\n",
    "    def __init__(self, num_features, num_conditions):\n",
    "        super().__init__()\n",
    "        self.bn = layers.BatchNormalization(center=False, scale=False)\n",
    "```\n",
    "Se crea una capa BatchNormalization, pero sin gamma ni beta aprendibles, porque se van a generar desde embeddings según una condición externa.\n",
    "\n",
    "```python\n",
    "        self.gamma = layers.Embedding(num_conditions, num_features, embeddings_initializer='ones')\n",
    "        self.beta = layers.Embedding(num_conditions, num_features, embeddings_initializer='zeros')\n",
    "```\n",
    "En lugar de usar parámetros fijos para todos los ejemplos, se usa una tabla de embeddings que mapea cada condición a un vector gamma y beta diferente.\n",
    "\n",
    "```python\n",
    "    def call(self, x, condition):\n",
    "        normalized = self.bn(x)\n",
    "```\n",
    "Normaliza x usando BatchNorm (solo con media y varianza).\n",
    "\n",
    "```python\n",
    "        gamma = self.gamma(condition)[:, tf.newaxis, tf.newaxis, :]\n",
    "        beta = self.beta(condition)[:, tf.newaxis, tf.newaxis, :]\n",
    "```\n",
    "Extrae el gamma y beta correspondientes a cada condición y les da forma para poder ser aplicados broadcasted al x (asumiendo que x es 4D: [batch, height, width, channels]).\n",
    "\n",
    "```python\n",
    "        return gamma * normalized + beta\n",
    "```\n",
    "Aplica el escalado y desplazamiento condicional.\n",
    "\n",
    "📌 Ejemplo de uso\n",
    "Imaginá que tenés una red generativa que genera imágenes de perros o gatos. La condition sería 0 para \"perro\", 1 para \"gato\". La capa aprende cómo normalizar de forma distinta según lo que se quiere generar.\n",
    "\n",
    "✅ ¿Cuándo usar ConditionalBatchNorm?\n",
    "En redes condicionales (Cond-GANs, StyleGAN, Conditional VAE).\n",
    "\n",
    "En aprendizaje multitarea o multiclase donde se necesita adaptar el comportamiento de la red según una señal externa.\n",
    "\n",
    "En visión por computadora cuando distintos dominios tienen estadísticas distintas (por ejemplo, estilos artísticos distintos)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff531e01",
   "metadata": {},
   "source": [
    "## ¿Que es un embeding?\n",
    "\n",
    "Un embedding es una representación numérica (vector) densa y de menor dimensión de datos categóricos o discretos, como palabras, clases o etiquetas. En lugar de usar representaciones simples como one-hot encoding, los embeddings permiten que estos datos sean representados en un espacio continuo donde se capturan relaciones semánticas o estructurales entre ellos.\n",
    "\n",
    "🎯 Ejemplo simple: categorías a vectores\n",
    "Supongamos que tenemos 3 clases:\n",
    "\n",
    "css\n",
    "Copiar\n",
    "['gato', 'perro', 'conejo']\n",
    "🔹 One-hot encoding\n",
    "css\n",
    "Copiar\n",
    "gato   → [1, 0, 0]\n",
    "perro  → [0, 1, 0]\n",
    "conejo → [0, 0, 1]\n",
    "Tiene dimensión 3\n",
    "\n",
    "Es esparso: muchos ceros\n",
    "\n",
    "No codifica ninguna relación entre categorías\n",
    "\n",
    "🔹 Embedding (por ejemplo, de dimensión 2)\n",
    "css\n",
    "Copiar\n",
    "gato   → [ 0.2, -0.1]\n",
    "perro  → [ 0.3, -0.2]\n",
    "conejo → [-0.5,  0.7]\n",
    "Tiene dimensión más baja (más eficiente)\n",
    "\n",
    "Es denso (valores continuos)\n",
    "\n",
    "Se puede aprender durante el entrenamiento\n",
    "\n",
    "📦 En TensorFlow / Keras:\n",
    "python\n",
    "Copiar\n",
    "tf.keras.layers.Embedding(input_dim=3, output_dim=2)\n",
    "Esto crea una tabla de embeddings de forma (3, 2) que se comporta como una \"lookup table\": si le das el índice 1, te devuelve el vector [0.3, -0.2].\n",
    "\n",
    "🧠 ¿Dónde se usa?\n",
    "Área\t¿Qué representa el embedding?\n",
    "Procesamiento de texto\tPalabras o tokens\n",
    "Sistemas de recomendación\tIDs de usuarios, productos\n",
    "Redes condicionales\tClases, condiciones, dominios\n",
    "Juegos / Ajedrez / RL\tEstados o acciones codificadas\n",
    "Tu código (ConditionalBatchNorm)\tLa clase/condición para modulación de parámetros\n",
    "\n",
    "⚙️ ¿Por qué son tan útiles?\n",
    "Reducen dimensionalidad\n",
    "\n",
    "Permiten que el modelo aprenda relaciones entre elementos\n",
    "\n",
    "Se entrenan como cualquier otro peso de la red (con backpropagation)\n",
    "\n",
    "Pueden generalizar a nuevas combinaciones o patrones\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e904b2",
   "metadata": {},
   "source": [
    "## Original pure CNN architecture:¶\n",
    "this version used a convultional network with a kernel size of 3 to learn the position's features. IN theory, useful for local features identification like pawn chains and structures, but can't make sense of long range relationships like threats, pins and attacks .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a297b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Model Architecture\n",
    "class ChessEvaluationCNN(Model):\n",
    "    def __init__(self, num_piece_channels=13, num_classes=1, num_conditions=2):\n",
    "        super(ChessEvaluationCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = layers.Conv2D(64, kernel_size=3, padding='same')\n",
    "        self.cbn1 = ConditionalBatchNorm(64, num_conditions)\n",
    "        self.conv2 = layers.Conv2D(128, kernel_size=3, padding='same')\n",
    "        self.cbn2 = ConditionalBatchNorm(128, num_conditions)\n",
    "        self.conv3 = layers.Conv2D(256, kernel_size=3, padding='same')\n",
    "        self.cbn3 = ConditionalBatchNorm(256, num_conditions)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc1 = layers.Dense(1024, activation='relu')\n",
    "        self.fc2 = layers.Dense(num_classes)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        board_tensor, active_player, halfmove_clock = inputs\n",
    "\n",
    "        # Forward pass\n",
    "        x = self.conv1(board_tensor)\n",
    "        x = self.cbn1(x, active_player)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.cbn2(x, active_player)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.cbn3(x, active_player)\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        # Global average pooling\n",
    "        x = tf.reduce_mean(x, axis=[1, 2])  # (batch_size, 256)\n",
    "        \n",
    "        # Fully connected layer with halfmove clock\n",
    "        x = tf.concat([self.fc1(x), tf.expand_dims(halfmove_clock, -1)], axis=1)\n",
    "        output = self.fc2(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff0af5a",
   "metadata": {},
   "source": [
    "## CNN + VIT\n",
    "Using a hybrid architecture consisting of convolutional network + vision transformer with the added benefit of self attention, giving the model the ability to learn long range piece relationships, highly scalable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaa1228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create patches for ViT\n",
    "def create_patches(x, patch_size):\n",
    "    # Dynamically get batch size and input dimensions\n",
    "    batch_size = tf.shape(x)[0]  # Dynamically fetch the actual batch size at runtime\n",
    "    channels = x.shape[1]  # Channels are known statically (13)\n",
    "    height = x.shape[2]     # Known statically (8)\n",
    "    width = x.shape[3]      # Known statically (8)\n",
    "\n",
    "    # Ensure the input is in the expected shape\n",
    "    if height != 8 or width != 8:\n",
    "        raise ValueError(\"Input dimensions for chessboard must be (None, 13, 8, 8)\")\n",
    "\n",
    "    # Reshape the input tensor to create patches\n",
    "    patches = tf.image.extract_patches(\n",
    "        images=tf.transpose(x, [0, 2, 3, 1]),  \n",
    "        sizes=[1, patch_size, patch_size, 1],\n",
    "        strides=[1, patch_size, patch_size, 1],\n",
    "        rates=[1, 1, 1, 1],\n",
    "        padding='VALID'\n",
    "    )\n",
    "\n",
    "    # Reshape the patches into (batch_size, num_patches, patch_dim)\n",
    "    patch_dim = patch_size * patch_size * channels \n",
    "    num_patches = (height // patch_size) * (width // patch_size)\n",
    "    \n",
    "    # Use static shape where possible to avoid runtime errors during XLA compilation\n",
    "    patches = tf.reshape(patches, [-1, num_patches, patch_dim])  # Use -1 for dynamic batch_size\n",
    "\n",
    "    return patches\n",
    "\n",
    "class ViTBlock(layers.Layer):\n",
    "    def __init__(self, num_heads, embed_dim, ff_dim):\n",
    "        super(ViTBlock, self).__init__()\n",
    "        self.attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            layers.Dense(ff_dim, activation='relu'),\n",
    "            layers.Dense(embed_dim)\n",
    "        ])\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        attn_output = self.attention(inputs, inputs)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "        return out2\n",
    "\n",
    "# Hybrid model definition (CNN + ViT)\n",
    "from keras.saving import register_keras_serializable\n",
    "\n",
    "@register_keras_serializable(package=\"ChessModel\")\n",
    "class ChessEvaluationHybridModel(Model):\n",
    "    def __init__(self, num_piece_channels=13, num_classes=1, num_conditions=2, patch_size=2):\n",
    "        super(ChessEvaluationHybridModel, self).__init__()\n",
    "        \n",
    "        self.num_piece_channels=num_piece_channels\n",
    "        self.num_classes=num_classes\n",
    "        self.num_conditions=num_conditions\n",
    "        self.patch_size=patch_size\n",
    "        \n",
    "        # CNN layers\n",
    "        self.conv1 = layers.Conv2D(64, kernel_size=3, padding='same')\n",
    "        self.cbn1 = ConditionalBatchNorm(64, num_conditions)\n",
    "        self.conv2 = layers.Conv2D(128, kernel_size=3, padding='same')\n",
    "        self.cbn2 = ConditionalBatchNorm(128, num_conditions)\n",
    "        self.conv3 = layers.Conv2D(256, kernel_size=3, padding='same')\n",
    "        self.cbn3 = ConditionalBatchNorm(256, num_conditions)\n",
    "        \n",
    "        # ViT layers\n",
    "        self.patch_size = patch_size\n",
    "        self.embedding_dim = (patch_size * patch_size) * num_piece_channels\n",
    "        self.vit_proj = layers.Dense(self.embedding_dim)  # Project patches into embedding space\n",
    "        \n",
    "        self.vit_block1 = ViTBlock(num_heads=4, embed_dim=self.embedding_dim, ff_dim=512)\n",
    "        self.vit_block2 = ViTBlock(num_heads=4, embed_dim=self.embedding_dim, ff_dim=512)\n",
    "        \n",
    "        self.flatten = layers.Flatten()\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = layers.Dense(1024, activation='relu')\n",
    "        self.fc2 = layers.Dense(num_classes)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        board_tensor, active_player, halfmove_clock = inputs\n",
    "\n",
    "        # CNN forward pass\n",
    "        x = self.conv1(board_tensor)\n",
    "        x = self.cbn1(x, active_player)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.cbn2(x, active_player)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.cbn3(x, active_player)\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        # ViT forward pass\n",
    "        patches = create_patches(board_tensor, self.patch_size)\n",
    "        patches = self.vit_proj(patches)\n",
    "        vit_out = self.vit_block1(patches)\n",
    "        vit_out = self.vit_block2(vit_out)\n",
    "        vit_out = tf.reduce_mean(vit_out, axis=1)  # Global average pooling for patches\n",
    "\n",
    "        # Combine CNN and ViT outputs\n",
    "        x = tf.concat([self.flatten(x), vit_out], axis=1)\n",
    "        \n",
    "        # Fully connected layers with halfmove clock\n",
    "        x = tf.concat([self.fc1(x), tf.expand_dims(halfmove_clock, -1)], axis=1)\n",
    "        output = self.fc2(x)\n",
    "        \n",
    "        return output\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        # Manually pass in the parameters here\n",
    "        return cls(\n",
    "            num_piece_channels=config['num_piece_channels'],\n",
    "            num_classes=config['num_classes'],\n",
    "            num_conditions=config['num_conditions'],\n",
    "            patch_size=config['patch_size']\n",
    "        )\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        # Include the custom arguments in the config dictionary\n",
    "        config.update({\n",
    "            'num_piece_channels': self.num_piece_channels,\n",
    "            'num_classes': self.num_classes,\n",
    "            'num_conditions': self.num_conditions,\n",
    "            'patch_size': self.patch_size\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09472876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement kaggle_secrets (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for kaggle_secrets\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kaggle_secrets'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m get_ipython().system(\u001b[33m'\u001b[39m\u001b[33mrm -rf /kaggle/working/*\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m#Replace with your own kaggle api as kaggle secrets input when copying this noteebook\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkaggle_secrets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UserSecretsClient\n\u001b[32m      7\u001b[39m user_secrets = UserSecretsClient()\n\u001b[32m      8\u001b[39m Api_key = user_secrets.get_secret(\u001b[33m\"\u001b[39m\u001b[33mKaggle Api\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'kaggle_secrets'"
     ]
    }
   ],
   "source": [
    "# %pip install kaggle_secrets\n",
    "#Loading previous version output using kaggle api \n",
    "!rm -rf /kaggle/working/*\n",
    "\n",
    "#Replace with your own kaggle api as kaggle secrets input when copying this noteebook\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "Api_key = user_secrets.get_secret(\"Kaggle Api\")\n",
    "\n",
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = 'oussamahaboubi'\n",
    "os.environ['KAGGLE_KEY'] = Api_key\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    saved_model=None\n",
    "    home_path=\"/kaggle/working/\"\n",
    "    for file in os.listdir(home_path):\n",
    "        if \".keras\" in file:\n",
    "            saved_model=home_path+file\n",
    "    return saved_model\n",
    "\n",
    "saved_model=get_model()\n",
    "if not saved_model:   \n",
    "    !kaggle kernels output oussamahaboubi/chess-evaluation-cnn-tensorflow -p /kaggle/working/\n",
    "    saved_model=get_model()\n",
    "\n",
    "# from tensorflow.keras.models import load_model\n",
    "# print(saved_model)\n",
    "\n",
    "# saved_model='/kaggle/working/checkpoint211120241650.model.keras'\n",
    "# model = ChessEvaluationHybridModel()\n",
    "# model = tf.keras.models.load_model(saved_model,custom_objects={'ChessEvaluationHybridModel': ChessEvaluationHybridModel})\n",
    "\n",
    "# Create model with manual config\n",
    "# model = ChessEvaluationHybridModel()\n",
    "# model=tf.keras.models.load_model(\"/kaggle/working/21-11-2024 19:51.keras\")\n",
    "\n",
    "# Now load the weights into the new model\n",
    "# model.load_weights(saved_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
