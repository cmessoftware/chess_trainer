{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4612da",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "kaggle datasets download ronakbadhe/chess-evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582fecfa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install chess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea00f0a0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, optimizers\n",
    "import pandas as pd\n",
    "import chess\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c23a08",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "piece_to_index = {\n",
    "    'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n",
    "    'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11\n",
    "}\n",
    "\n",
    "# Helper functions to convert FEN to tensor\n",
    "def fen_to_tensor(fen):\n",
    "    board = chess.Board(fen)\n",
    "    board_tensor = np.zeros((13, 8, 8), dtype=np.float32)\n",
    "    \n",
    "    # Castling mapping\n",
    "    castling_map = {'K': (7, 6), 'Q': (7, 2), 'k': (0, 6), 'q': (0, 2)}\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            row, col = 7 - chess.square_rank(square), chess.square_file(square)\n",
    "            board_tensor[piece_to_index[piece.symbol()], row, col] = 1\n",
    "\n",
    "    # FEN features\n",
    "    fen_parts = fen.split()\n",
    "    active_player = 1 if fen_parts[1] == 'w' else 0\n",
    "    halfmove_clock = float(fen_parts[4]) / 100.0\n",
    "    en_passant = fen_parts[3]\n",
    "    castle_rights = fen_parts[2]\n",
    "    \n",
    "    # Encode en passant\n",
    "    if en_passant != '-':\n",
    "        row, col = 7 - (int(en_passant[1]) - 1), ord(en_passant[0]) - ord('a')\n",
    "        board_tensor[12, row, col] = 1\n",
    "\n",
    "    # Encode castling rights\n",
    "    if castle_rights != '-':\n",
    "        for right in castle_rights:\n",
    "            row, col = castling_map[right]\n",
    "            board_tensor[12, row, col] = 1\n",
    "\n",
    "    return board_tensor, active_player, halfmove_clock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a15135",
   "metadata": {},
   "source": [
    "## Load dataset from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fad370",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_data(csv_path,sample_size=1000):\n",
    "    data = pd.read_csv(csv_path)\n",
    "    data = data.sample(n=sample_size, random_state=42)\n",
    "    boards, active_players, halfmove_clocks, evaluations = [], [], [], []\n",
    "    for idx, row in data.iterrows():\n",
    "        board_tensor, active_player, halfmove_clock = fen_to_tensor(row['FEN'])\n",
    "        boards.append(board_tensor)\n",
    "        active_players.append(active_player)\n",
    "        halfmove_clocks.append(halfmove_clock)\n",
    "        evaluation=row['Evaluation']\n",
    "\n",
    "        if evaluation.startswith('#'):\n",
    "            # Converting checkmate to large positive/negative values\n",
    "            if evaluation[1] == '-':\n",
    "                # Negative checkmate (opponent checkmating)\n",
    "                evaluation = -10000.0  # Arbitrary large negative value\n",
    "            else:\n",
    "                # Positive checkmate (current player checkmating)\n",
    "                evaluation = 10000.0  # Arbitrary large positive value\n",
    "        else:\n",
    "            # Standard centipawn evaluation to float\n",
    "            evaluation = float(evaluation)\n",
    "        \n",
    "        evaluations.append(evaluation)\n",
    "\n",
    "    boards = np.array(boards)\n",
    "    active_players = np.array(active_players)\n",
    "    halfmove_clocks = np.array(halfmove_clocks)\n",
    "    evaluations = np.array(evaluations)\n",
    "    return boards, active_players, halfmove_clocks, evaluations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a027b7",
   "metadata": {},
   "source": [
    "## Data loader + Label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bf55fb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Custom Conditional Batch Norm Layer\n",
    "class ConditionalBatchNorm(layers.Layer):\n",
    "    def __init__(self, num_features, num_conditions):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.bn = layers.BatchNormalization(center=False, scale=False)\n",
    "        self.gamma = layers.Embedding(num_conditions, num_features, embeddings_initializer='ones')\n",
    "        self.beta = layers.Embedding(num_conditions, num_features, embeddings_initializer='zeros')\n",
    "\n",
    "    def call(self, x, condition):\n",
    "        normalized = self.bn(x)\n",
    "        gamma = self.gamma(condition)[:, tf.newaxis, tf.newaxis, :]\n",
    "        beta = self.beta(condition)[:, tf.newaxis, tf.newaxis, :]\n",
    "        return gamma * normalized + beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ace0f9",
   "metadata": {},
   "source": [
    "## Model architecture\n",
    "**Conditional Batch Normalization**\n",
    "Used to distinguish between black & white turns to play when training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f986cc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "class ChessEvaluationCNN(Model):\n",
    "    def __init__(self, num_piece_channels=13, num_classes=1, num_conditions=2):\n",
    "        super(ChessEvaluationCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = layers.Conv2D(64, kernel_size=3, padding='same')\n",
    "        self.cbn1 = ConditionalBatchNorm(64, num_conditions)\n",
    "        self.conv2 = layers.Conv2D(128, kernel_size=3, padding='same')\n",
    "        self.cbn2 = ConditionalBatchNorm(128, num_conditions)\n",
    "        self.conv3 = layers.Conv2D(256, kernel_size=3, padding='same')\n",
    "        self.cbn3 = ConditionalBatchNorm(256, num_conditions)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc1 = layers.Dense(1024, activation='relu')\n",
    "        self.fc2 = layers.Dense(num_classes)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        board_tensor, active_player, halfmove_clock = inputs\n",
    "\n",
    "        # Forward pass\n",
    "        x = self.conv1(board_tensor)\n",
    "        x = self.cbn1(x, active_player)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.cbn2(x, active_player)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.cbn3(x, active_player)\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        # Global average pooling\n",
    "        x = tf.reduce_mean(x, axis=[1, 2])  # (batch_size, 256)\n",
    "        \n",
    "        # Fully connected layer with halfmove clock\n",
    "        x = tf.concat([self.fc1(x), tf.expand_dims(halfmove_clock, -1)], axis=1)\n",
    "        output = self.fc2(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a522c64",
   "metadata": {},
   "source": [
    "## Original pure CNN architecture:\n",
    "This version used a convultional network with a kernel size of 3 to learn the position's features. IN theory, useful for local features identification like pawn chains and structures, but can't make sense of long range relationships like threats, pins and attacks .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2850c9b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "class ChessEvaluationCNN(Model):\n",
    "    def __init__(self, num_piece_channels=13, num_classes=1, num_conditions=2):\n",
    "        super(ChessEvaluationCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = layers.Conv2D(64, kernel_size=3, padding='same')\n",
    "        self.cbn1 = ConditionalBatchNorm(64, num_conditions)\n",
    "        self.conv2 = layers.Conv2D(128, kernel_size=3, padding='same')\n",
    "        self.cbn2 = ConditionalBatchNorm(128, num_conditions)\n",
    "        self.conv3 = layers.Conv2D(256, kernel_size=3, padding='same')\n",
    "        self.cbn3 = ConditionalBatchNorm(256, num_conditions)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc1 = layers.Dense(1024, activation='relu')\n",
    "        self.fc2 = layers.Dense(num_classes)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        board_tensor, active_player, halfmove_clock = inputs\n",
    "\n",
    "        # Forward pass\n",
    "        x = self.conv1(board_tensor)\n",
    "        x = self.cbn1(x, active_player)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.cbn2(x, active_player)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.cbn3(x, active_player)\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        # Global average pooling\n",
    "        x = tf.reduce_mean(x, axis=[1, 2])  # (batch_size, 256)\n",
    "        \n",
    "        # Fully connected layer with halfmove clock\n",
    "        x = tf.concat([self.fc1(x), tf.expand_dims(halfmove_clock, -1)], axis=1)\n",
    "        output = self.fc2(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ac7e5e",
   "metadata": {},
   "source": [
    "## CNN + VIT\n",
    "Using a hybrid architecture consisting of convolutional network + vision transformer with the added benefit of self attention, giving the model the ability to learn long range piece relationships, highly scalable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5be34f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Helper function to create patches for ViT\n",
    "def create_patches(x, patch_size):\n",
    "    # Dynamically get batch size and input dimensions\n",
    "    batch_size = tf.shape(x)[0]  # Dynamically fetch the actual batch size at runtime\n",
    "    channels = x.shape[1]  # Channels are known statically (13)\n",
    "    height = x.shape[2]     # Known statically (8)\n",
    "    width = x.shape[3]      # Known statically (8)\n",
    "\n",
    "    # Ensure the input is in the expected shape\n",
    "    if height != 8 or width != 8:\n",
    "        raise ValueError(\"Input dimensions for chessboard must be (None, 13, 8, 8)\")\n",
    "\n",
    "    # Reshape the input tensor to create patches\n",
    "    patches = tf.image.extract_patches(\n",
    "        images=tf.transpose(x, [0, 2, 3, 1]),  \n",
    "        sizes=[1, patch_size, patch_size, 1],\n",
    "        strides=[1, patch_size, patch_size, 1],\n",
    "        rates=[1, 1, 1, 1],\n",
    "        padding='VALID'\n",
    "    )\n",
    "\n",
    "    # Reshape the patches into (batch_size, num_patches, patch_dim)\n",
    "    patch_dim = patch_size * patch_size * channels \n",
    "    num_patches = (height // patch_size) * (width // patch_size)\n",
    "    \n",
    "    # Use static shape where possible to avoid runtime errors during XLA compilation\n",
    "    patches = tf.reshape(patches, [-1, num_patches, patch_dim])  # Use -1 for dynamic batch_size\n",
    "\n",
    "    return patches\n",
    "\n",
    "class ViTBlock(layers.Layer):\n",
    "    def __init__(self, num_heads, embed_dim, ff_dim):\n",
    "        super(ViTBlock, self).__init__()\n",
    "        self.attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            layers.Dense(ff_dim, activation='relu'),\n",
    "            layers.Dense(embed_dim)\n",
    "        ])\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        attn_output = self.attention(inputs, inputs)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "        return out2\n",
    "\n",
    "# Hybrid model definition (CNN + ViT)\n",
    "from keras.saving import register_keras_serializable\n",
    "\n",
    "@register_keras_serializable(package=\"ChessModel\")\n",
    "class ChessEvaluationHybridModel(Model):\n",
    "    def __init__(self, num_piece_channels=13, num_classes=1, num_conditions=2, patch_size=2):\n",
    "        super(ChessEvaluationHybridModel, self).__init__()\n",
    "        \n",
    "        self.num_piece_channels=num_piece_channels\n",
    "        self.num_classes=num_classes\n",
    "        self.num_conditions=num_conditions\n",
    "        self.patch_size=patch_size\n",
    "        \n",
    "        # CNN layers\n",
    "        self.conv1 = layers.Conv2D(64, kernel_size=3, padding='same')\n",
    "        self.cbn1 = ConditionalBatchNorm(64, num_conditions)\n",
    "        self.conv2 = layers.Conv2D(128, kernel_size=3, padding='same')\n",
    "        self.cbn2 = ConditionalBatchNorm(128, num_conditions)\n",
    "        self.conv3 = layers.Conv2D(256, kernel_size=3, padding='same')\n",
    "        self.cbn3 = ConditionalBatchNorm(256, num_conditions)\n",
    "        \n",
    "        # ViT layers\n",
    "        self.patch_size = patch_size\n",
    "        self.embedding_dim = (patch_size * patch_size) * num_piece_channels\n",
    "        self.vit_proj = layers.Dense(self.embedding_dim)  # Project patches into embedding space\n",
    "        \n",
    "        self.vit_block1 = ViTBlock(num_heads=4, embed_dim=self.embedding_dim, ff_dim=512)\n",
    "        self.vit_block2 = ViTBlock(num_heads=4, embed_dim=self.embedding_dim, ff_dim=512)\n",
    "        \n",
    "        self.flatten = layers.Flatten()\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = layers.Dense(1024, activation='relu')\n",
    "        self.fc2 = layers.Dense(num_classes)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        board_tensor, active_player, halfmove_clock = inputs\n",
    "\n",
    "        # CNN forward pass\n",
    "        x = self.conv1(board_tensor)\n",
    "        x = self.cbn1(x, active_player)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.cbn2(x, active_player)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.cbn3(x, active_player)\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        # ViT forward pass\n",
    "        patches = create_patches(board_tensor, self.patch_size)\n",
    "        patches = self.vit_proj(patches)\n",
    "        vit_out = self.vit_block1(patches)\n",
    "        vit_out = self.vit_block2(vit_out)\n",
    "        vit_out = tf.reduce_mean(vit_out, axis=1)  # Global average pooling for patches\n",
    "\n",
    "        # Combine CNN and ViT outputs\n",
    "        x = tf.concat([self.flatten(x), vit_out], axis=1)\n",
    "        \n",
    "        # Fully connected layers with halfmove clock\n",
    "        x = tf.concat([self.fc1(x), tf.expand_dims(halfmove_clock, -1)], axis=1)\n",
    "        output = self.fc2(x)\n",
    "        \n",
    "        return output\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        # Manually pass in the parameters here\n",
    "        return cls(\n",
    "            num_piece_channels=config['num_piece_channels'],\n",
    "            num_classes=config['num_classes'],\n",
    "            num_conditions=config['num_conditions'],\n",
    "            patch_size=config['patch_size']\n",
    "        )\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        # Include the custom arguments in the config dictionary\n",
    "        config.update({\n",
    "            'num_piece_channels': self.num_piece_channels,\n",
    "            'num_classes': self.num_classes,\n",
    "            'num_conditions': self.num_conditions,\n",
    "            'patch_size': self.patch_size\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10060752",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Loading previous version output using kaggle api \n",
    "!rm -rf /kaggle/working/*\n",
    "\n",
    "#Replace with your own kaggle api as kaggle secrets input when copying this noteebook\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "Api_key = user_secrets.get_secret(\"Kaggle Api\")\n",
    "\n",
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = 'oussamahaboubi'\n",
    "os.environ['KAGGLE_KEY'] = Api_key\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    saved_model=None\n",
    "    home_path=\"/kaggle/working/\"\n",
    "    for file in os.listdir(home_path):\n",
    "        if \".keras\" in file:\n",
    "            saved_model=home_path+file\n",
    "    return saved_model\n",
    "\n",
    "saved_model=get_model()\n",
    "if not saved_model:   \n",
    "    !kaggle kernels output oussamahaboubi/chess-evaluation-cnn-tensorflow -p /kaggle/working/\n",
    "    saved_model=get_model()\n",
    "\n",
    "# from tensorflow.keras.models import load_model\n",
    "# print(saved_model)\n",
    "\n",
    "# saved_model='/kaggle/working/checkpoint211120241650.model.keras'\n",
    "# model = ChessEvaluationHybridModel()\n",
    "# model = tf.keras.models.load_model(saved_model,custom_objects={'ChessEvaluationHybridModel': ChessEvaluationHybridModel})\n",
    "\n",
    "# Create model with manual config\n",
    "# model = ChessEvaluationHybridModel()\n",
    "# model=tf.keras.models.load_model(\"/kaggle/working/21-11-2024 19:51.keras\")\n",
    "\n",
    "# Now load the weights into the new model\n",
    "# model.load_weights(saved_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a6bb97",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18a82f4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class LossHistory(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.losses = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Append the loss at the end of each epoch\n",
    "        self.losses.append(logs.get('loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073d386a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare TensorFlow dataset\n",
    "SAMPLE_SIZE=1000000\n",
    "EPOCHS=200\n",
    "BATCH_SIZE=512\n",
    "boards, active_players, halfmove_clocks, evaluations = load_data('/kaggle/input/chess-evaluations/random_evals.csv',sample_size=SAMPLE_SIZE)\n",
    "\n",
    "inputs = (boards, active_players, halfmove_clocks)\n",
    "targets = evaluations\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, targets))\n",
    "dataset = dataset.shuffle(buffer_size=2048).batch(BATCH_SIZE)\n",
    "\n",
    "loss_history = LossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674c92c7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "checkpoint_filepath = \"model.keras\"#f'checkpoint{now}.model.keras'\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.005,\n",
    "    decay_steps=20000,\n",
    "    decay_rate=0.9)\n",
    "\n",
    "optimizer=optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "\n",
    "# Compile and train the model\n",
    "model = ChessEvaluationHybridModel()\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "model.load_weights(saved_model)\n",
    "\n",
    "\n",
    "model.fit(dataset,epochs=EPOCHS, callbacks=[loss_history,model_checkpoint_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2153172",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'Epoch': range(1, EPOCHS + 1), 'Loss': loss_history.losses})\n",
    "\n",
    "# Plot the loss curve\n",
    "plt.plot(df['Epoch'], df['Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss (Logarithmic Scale)')\n",
    "plt.yscale('log')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b5bb59",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "model.save(f'/kaggle/working/{now}.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af4062d",
   "metadata": {},
   "source": [
    "## Testing Saved Models\n",
    "Latest Checkpoint\n",
    "using the latest checkpoint generated with model.Save, which ended at around 24k loss value and rising, reassigning the optimizer starts from a higher loss ,around 230K and decreasing quickly. But not as bad as training the model from the ground up.\n",
    "\n",
    "These losses sugget possible issues like local minima, overfitting, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf8131d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model2=tf.keras.models.load_model(\"/kaggle/working/22-11-2024 00:41:15.keras\", custom_objects={\"ChessEvaluationHybridModel\":ChessEvaluationHybridModel})\n",
    "\n",
    "lr_schedule2 = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.0001,\n",
    "    decay_steps=20000,\n",
    "    decay_rate=0.9)\n",
    "\n",
    "optimizer2=optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model2.compile(optimizer=optimizer2, loss='mse')\n",
    "model2.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc665a2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model3=tf.keras.models.load_model(\"/kaggle/working/22-11-2024 00:41:14.keras\", custom_objects={\"ChessEvaluationHybridModel\":ChessEvaluationHybridModel})\n",
    "\n",
    "model3.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13117b5b",
   "metadata": {},
   "source": [
    "## Best checkpoint\n",
    "Using the callback checkpoint allows us to continue training from the lowest loss point of the model, However this still runs into the issue of increasing loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0003e94",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model4=tf.keras.models.load_model(\"/kaggle/working/model.keras\", custom_objects={\"ChessEvaluationHybridModel\":ChessEvaluationHybridModel})\n",
    "\n",
    "model4.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16eeb95",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model5=tf.keras.models.load_model(\"/kaggle/working/model.keras\", custom_objects={\"ChessEvaluationHybridModel\":ChessEvaluationHybridModel})\n",
    "\n",
    "lr_schedule3 = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.0001,\n",
    "    decay_steps=20000,\n",
    "    decay_rate=0.9)\n",
    "\n",
    "optimizer3=optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model5.compile(optimizer=optimizer3, loss='mse')\n",
    "model5.fit(dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de543cec",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
